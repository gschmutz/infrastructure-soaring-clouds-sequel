version: '2'

services:
  zookeeper-1:
    image: 'confluentinc/cp-zookeeper:5.3.0'
    container_name: zookeeper-1
    ports:
      - '2181:2181/tcp'
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    restart: always
    
  broker-1:
    image: 'confluentinc/cp-enterprise-kafka:5.3.0'
    container_name: broker-1
    ports:
      - '9092:9092/tcp'
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_BROKER_RACK=rack-a
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper-1:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${PUBLIC_IP}:9092
      - KAFKA_DELETE_TOPIC_ENABLE=true
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_JMX_PORT=9999
      - KAFKA_JMX_HOSTNAME=broker-1
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    restart: always
    
  broker-2:
    image: 'confluentinc/cp-enterprise-kafka:5.3.0'
    container_name: broker-2
    ports:
      - '9093:9093/tcp'
    environment:
      - KAFKA_BROKER_ID=2
      - KAFKA_BROKER_RACK=rack-a
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper-1:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${PUBLIC_IP}:9093
      - KAFKA_DELETE_TOPIC_ENABLE=true
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_JMX_PORT=9998
      - KAFKA_JMX_HOSTNAME=broker-2
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    restart: always

  broker-3:
    image: 'confluentinc/cp-enterprise-kafka:5.3.0'
    container_name: broker-3
    ports:
      - '9094:9094/tcp'
    environment:
      - KAFKA_BROKER_ID=3
      - KAFKA_BROKER_RACK=rack-a
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper-1:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${PUBLIC_IP}:9094
      - KAFKA_DELETE_TOPIC_ENABLE=true
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_JMX_PORT=9997
      - KAFKA_JMX_HOSTNAME=broker-3
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    restart: always
        
  connect-1:
    image: confluentinc/cp-kafka-connect:5.3.0
    container_name: connect-1
    depends_on:
      - zookeeper-1
      - broker-1
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-1:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect-1
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/custom-plugins"
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-4.0.0.jar
    volumes:
      - $PWD/kafka-connect:/etc/kafka-connect/custom-plugins
    restart: always      

  connect-2:
    image: confluentinc/cp-kafka-connect:5.3.0
    container_name: connect-2
    depends_on:
      - zookeeper-1
      - broker-1
      - schema-registry
    ports:
      - "8084:8084"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-1:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect-2
      CONNECT_REST_PORT: 8084
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/custom-plugins"
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-4.0.0.jar
    volumes:
      - $PWD/kafka-connect:/etc/kafka-connect/custom-plugins
    restart: always
            
  schema-registry:
    image: 'confluentinc/cp-schema-registry:5.1.0'
    container_name: schema-registry
    ports:
      - '8081:8081/tcp'
    environment:
      - SCHEMA_REGISTRY_HOST_NAME=schema_registry
      - 'SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper-1:2181'
      - SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN=*
      - 'SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS=GET,POST,PUT,OPTIONS'
    restart: always

  kafka-setup:
    image: confluentinc/cp-kafka:5.3.0
    hostname: kafka-setup
    container_name: kafka-setup
    depends_on:
      - broker-1
      - broker-2
      - broker-3
      - zookeeper-1
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b broker-1:9092 1 240 && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-add-to-shopping-cart && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-customers && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-customerstatus && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-ordercreated && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-paymentstatus && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-products && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-shippingnews && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 1 --replication-factor 3 --topic soaring-usersignins && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 1 --replication-factor 3 --topic soaring-shipmentoffer && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 1 --replication-factor 3 --topic soaring-shipmentpickedup && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 8 --replication-factor 3 --topic soaring-shipmentreceived && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 1 --replication-factor 3 --topic soaring-orderpicked && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 1 --replication-factor 3 --topic soaring-shipmentrequestissued
                 '"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored            

  kafka-manager:
    image: trivadisbds/kafka-manager
    container_name: kafka-manager
    links:
      - broker-1
    ports:
      - '9000:9000/tcp'
    environment:
      - ZK_HOSTS=zookeeper-1:2181
      - APPLICATION_SECRET=letmein
    restart: always
    
  kafkahq:
    image: tchiotludo/kafkahq
    container_name: kafkahq
    ports:
      - 28082:8080
    environment:
      KAFKAHQ_CONFIGURATION: |
        kafkahq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "broker-1:9092"
              schema-registry: "http://schema-registry:8085"
    depends_on:
      - broker-1
    restart: always  
          
  schema-registry-ui:
    image: landoop/schema-registry-ui
    container_name: schema-registry-ui
    ports:
      - '8002:8000/tcp'
    environment:
      - 'SCHEMAREGISTRY_URL=http://${PUBLIC_IP}:8081'
    restart: always  

  kafka-connect-ui:
    image: landoop/kafka-connect-ui
    container_name: kafka-connect-ui
    ports:
      - "28001:8000"
    environment:
      CONNECT_URL: "http://${PUBLIC_IP}:8083/,http://${PUBLIC_IP}:8084/"
      PROXY: "true"
    depends_on:
      - connect-1
    restart: always
        
  mongo-prod:
    image: mongo:latest
    container_name: mongo-prod
    ports:
      - 27017:27017
    #environment:
    #  - MONGODB_USER=debezium
    #  - MONGODB_PASSWORD=dbz
    restart: always
    
  product:
    image: gschmutz/product-soaring-clouds-sequel
    container_name: product
    environment:
      - KAFKA_BOOTSTRAP-SERVERS=broker-1:9092
      - SPRING_KAFKA_SCHEMA-REGISTRY-URL=http://${PUBLIC_IP}:8081
      - SPRING_DATA_MONGODB_ADDRESS=mongo-prod
      - KAFKA_TOPIC_ADDTOSHOPPINGCART=soaring-add-to-shopping-cart
      - KAFKA_TOPIC_PRODUCT=soaring-products
    ports:
      - 8080:8080
    restart: always
    
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.7.0
    hostname: elasticsearch
    container_name: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      xpack.security.enabled: "false"
      XPACK_SECURITY_ENABLED: "false"
      xpack.monitoring.enabled: "false"
    restart: always
